{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16a9da42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'input.shape=torch.Size([32, 5, 5]); output.shape=torch.Size([32, 5, 150])'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from app.model.config import Config\n",
    "from app.model.time_series_embedding import TimeSeriesEmbedding\n",
    "\n",
    "data_dir = Path('app/data')\n",
    "config = Config(data_dir)\n",
    "time_series_embedding = TimeSeriesEmbedding(config)\n",
    "input = torch.randn(32, config.seq_len, config.input_dims)\n",
    "output = time_series_embedding(input)\n",
    "\n",
    "display(f'{input.shape=}; {output.shape=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e817edf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'input.shape=torch.Size([32, 5, 150]); output.shape=torch.Size([32, 5, 150])'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from app.model.config import Config\n",
    "from app.model.positional_encoding import PositionalEncoding\n",
    "\n",
    "data_dir = Path('app/data')\n",
    "config = Config(data_dir)\n",
    "positional_encoding = PositionalEncoding(config)\n",
    "input = torch.randn((32, config.seq_len, config.d_model))\n",
    "output = positional_encoding(input)\n",
    "\n",
    "display(f'{input.shape=}; {output.shape=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7acff00e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'input.shape=torch.Size([16, 5, 5])'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'output.shape=torch.Size([16, 1])'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from app.model.config import Config\n",
    "from app.model.stock_transformer import StockTransformer\n",
    "\n",
    "\n",
    "data_dir = Path('app/data')\n",
    "config = Config(data_dir)\n",
    "input = torch.randn((config.batch_size, config.seq_len, config.input_dims),\n",
    "                    dtype=torch.float)\n",
    "display(f'{input.shape=}')\n",
    "transformer = StockTransformer(config)\n",
    "output = transformer(input)\n",
    "display(f'{output.shape=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d8d997e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved app/data/tickers/SPY_19930129_20251231.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import yfinance as yf\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "ticker = 'SPY'\n",
    "data = yf.Ticker(ticker)\n",
    "hist = data.history(period='max', interval='1d')\n",
    "\n",
    "if hist.empty:\n",
    "    print(f'No data available for {ticker}')\n",
    "else:\n",
    "    date_from = hist.index.min().strftime('%Y%m%d')\n",
    "    date_to = hist.index.max().strftime('%Y%m%d')\n",
    "\n",
    "    out_dir = Path('app/data') / 'tickers'\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_path = out_dir / f\"{ticker}_{date_from}_{date_to}.csv\"\n",
    "\n",
    "    columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    with out_path.open('w', newline='') as fp:\n",
    "        writer = csv.writer(fp)\n",
    "        writer.writerow(columns)\n",
    "        for row in hist.itertuples():\n",
    "            writer.writerow([getattr(row, c) for c in columns])\n",
    "\n",
    "    print(f'Saved {out_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54196eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from app/data/models/4000/SPY.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[2.4259e+01, 2.4259e+01, 2.4138e+01, 2.4241e+01, 1.0032e+06,\n",
       "          0.0000e+00],\n",
       "         [2.4259e+01, 2.4414e+01, 2.4259e+01, 2.4414e+01, 4.8050e+05,\n",
       "          7.0870e-03],\n",
       "         [2.4397e+01, 2.4483e+01, 2.4345e+01, 2.4466e+01, 2.0130e+05,\n",
       "          2.1160e-03],\n",
       "         [2.4500e+01, 2.4741e+01, 2.4483e+01, 2.4724e+01, 5.2940e+05,\n",
       "          1.0515e-02],\n",
       "         [2.4810e+01, 2.4879e+01, 2.4535e+01, 2.4828e+01, 5.3150e+05,\n",
       "          4.1750e-03]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0023]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "24.827604293823242"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "24.8835506439209"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "from app.model.checkpointer import Checkpointer\n",
    "\n",
    "model_path = Path('app/data/models/4000/SPY.pkl')\n",
    "model, config, step = Checkpointer.load_checkpoint(model_path)\n",
    "input = torch.tensor([\n",
    "    [[24.25864879369397, 24.25864879369397,\n",
    "        24.137958998700466, 24.24140739440918, 1003200, 0.000000],\n",
    "     [24.258645785056938, 24.413818359374996,\n",
    "        24.258645785056938, 24.413818359375, 480500, 0.007087],\n",
    "     [24.396570547102538, 24.482777510166507,\n",
    "        24.344846369264157, 24.46553611755371, 201300, 0.002116],\n",
    "     [24.500017336389178, 24.74139681753587,\n",
    "        24.4827759448787, 24.72415542602539, 529400, 0.010515],\n",
    "     [24.810362901952534, 24.879328469435375,\n",
    "        24.534500632021164, 24.827604293823242, 531500, 0.004175]]\n",
    "])\n",
    "output = model(input)\n",
    "display(input, output)\n",
    "last_close = input[:, -1, -3].item()\n",
    "predicted_log_return = output[0][0]\n",
    "predicted_close = last_close * torch.exp(predicted_log_return)\n",
    "display(last_close, predicted_close.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
